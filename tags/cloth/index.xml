<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloth | QINGYANG TAN</title>
    <link>/tags/cloth/</link>
      <atom:link href="/tags/cloth/index.xml" rel="self" type="application/rss+xml" />
    <description>Cloth</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019 Qingyang Tan</copyright><lastBuildDate>Tue, 17 Dec 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Cloth</title>
      <link>/tags/cloth/</link>
    </image>
    
    <item>
      <title>Nonlinear Subspace Cloth Simulation</title>
      <link>/project/828x/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/project/828x/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br /&gt;
Qingyang Tan (&lt;a href=&#34;mailto:qytan@cs.umd.edu&#34; target=&#34;_blank&#34;&gt;qytan@cs.umd.edu&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;br /&gt;
In this project, we want to build a cloth simulator in a nonlinear subspace to reduce the search space. We leverage the graph-based convolutional neural network (GCNN) with a physical-inspired loss term to build an embedding network for cloth models. We then use mass-spring systems or finite-element method (FEM) to model the cloth energy and build a simulator based on the nonlinear embedded space. We show that using the proposed method can better capture cloth deformation and generalize on new control information well.&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Cloth simulation has applications in different areas, including animation, robotic control, gaming. Usually, the cloth is modeled as a 2D thin-shell object in a 3D space and represented by a high-resolution mesh. Many techniques have been developed to simulate the deformation of cloth in this mesh-based representation, including the mass-spring systems [1], the finite-element method [2]. However, the complexity of these methods depends on the number of degrees of freedoms (DOF), vary from $\mathcal{O}(n^{1.5})$ to $\mathcal{O}(n^{3})$. It would be hard to deploy high-resolution cloth simulation on devices with limited computation resources, e.g., cell phones.&lt;/p&gt;

&lt;p&gt;Data-driven methods have been proposed to accelerate the simulation process. These kinds of methods leverage the results from pre-computation to accelerate run-time simulation process. Previous works including non-learning methods, such as motion graph [3], and learning-based methods, such as subspace simulation [4, 5] and frame predictor [6, 7]. However, previous methods may suffer from loss of details or freedom of new control information.&lt;/p&gt;

&lt;p&gt;In our project, we propose to combine GCNN based neural network embedding [8] and subspace integration to capture more details of cloth deformation while allowing full freedom to control the cloth simulation.&lt;/p&gt;

&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;

&lt;p&gt;We will briefly discuss previous works in this section.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Motion Graph&lt;/strong&gt;&lt;br /&gt;
[3] proposes to incrementally construct a secondary cloth motion to capture almost everything in the system and then compress the raw mesh data from tens of gigabytes to only tens of megabytes. This method allows the system to capture the effect of high-resolution, off-line cloth simulation for a rich space of character motion and deliver it efﬁciently as part of an interactive application. However, the simulation is fully constrained by pre-computation and it can only deliver results explored during construction. We want to use subspace integration to give users full control of the cloth simulation process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subspace Integration&lt;/strong&gt;&lt;br /&gt;
[4, 5] both conduct subspace integration to accelerate model simulation. [4] uses mass-scaled principal component analysis (mass-PCA), which is a linear model. [5] uses a fully-connected autoencoder based on PCA results, which is not computationally efficient and is constrained with the linear PCA basis. Thus, both methods cannot capture the nonlinear deformation well of cloth material. We propose to leverage the power of GCNN to exploit the subspace of cloth models and increase the accuracy of deformation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Frame Predictor&lt;/strong&gt;&lt;br /&gt;
[6, 7] use machine learning methods to model the simulation process of cloth. Use linear regression or neural network-based method to predict the next frame given control parameters and previous few frames. These methods can be very quick since they do not require heavy computation of the physics model. However, this scheme can easily let the system be overfitted on training data, and it would behave badly on the new unseen control information, as we will show in the result section. So we stick to model the physics law explicitly.&lt;/p&gt;

&lt;h2 id=&#34;proposed-method&#34;&gt;Proposed Method&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;GCNN-based Embedding&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In this section, we provide an overview of low-dimensional embedding of the cloth meshes. Our goal is to obtain a subspace through a set of $N$ deformed cloth meshes, $S_m$, with each mesh represented using a set of $K$ vertices, denoted as $\mathbf{p}_m\in\mathbb{R}^{3K}$.&lt;/p&gt;

&lt;p&gt;We denote the $i$th vertex as $\mathbf{p}_{m,i}\in\mathbb{R}^3$. Here $m=1,\cdots,N$ and $i=1,\cdots,K$. These vertices are connected by edges, so we can define the 1-ring neighbor set, $\mathcal{N}^1_i$, and the 2-ring neighbor set, $\mathcal{N}^2_i$, for each $\mathbf{p}_i$. Our goal is to find a map $\mathbf{z}\to\mathbf{p}$, where $\mathbf{z}$ is a low-dimensional feature and $\mathbf{p}\in\mathbf{R}^{3K}$ such that, for each $m$, there exists a $\mathbf{z}_m$ where $\mathbf{z}_m$ is mapped to a mesh close to $\mathbf{p}_m$. To define such a function $\mathbf{D}$, we use graph-based CNN and ACAP features [8] to represent large-scale deformations.&lt;/p&gt;

&lt;p&gt;We define $\mathbf{D}$ as a graph-based CNN using local filters
$$
\mathbf{D}\triangleq\mathbf{C}_L^T\cdots\mathbf{C}_2^T\circ\mathbf{C}_1^T\circ\mathbf{F}^T,
$$
where $L$ is the number of convolutional layers and $\mathbf{C}^T$ is the transpose of a graph-based convolutional operator, $\mathbf{F}$ is a fully connected layer. Each layer is appended by a leaky ReLU activation layer.&lt;/p&gt;

&lt;p&gt;A graph-based convolutional layer is a linear operator defined as:
$$
\mathbf{C}(\mathbf{x})_i = \mathbf{W}\mathbf{x}_i+\mathbf{W_N}(\Sigma_j\mathbf{x}_j)/N_i + b
$$
where $\mathbf{W},\mathbf{W_N}, b$ are optimizable weights and biases, respectively; $j$ is the index of neighbors of $i$ and $N_i$ is the degree of vertex $i$.&lt;/p&gt;

&lt;p&gt;All the weights in the CNN are trained in a self-supervised manner using an autoencoder and a reconstruction loss in ACAP feature and physical-inspired loss mentioned in the later section.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model the Physics of Cloth Deformation&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;experimental-results&#34;&gt;Experimental Results&lt;/h2&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;br /&gt;
[1] K.-J. Choi and H.-S. Ko, “Stable but responsive cloth,” in SIGGRAPH 2002.&lt;br /&gt;
[2] R. Narain, A. Samii, and J. F. O’Brien, “Adaptive anisotropic remeshing for cloth simulation,”  ACM TOG, 2002.&lt;br /&gt;
[3] D. Kim, W. Koh, R. Narain, K. Fatahalian, A. Treuille, and J. F. O’Brien, “Near-exhaustive precomputation of secondary cloth effects,” ACM TOG, 2013.&lt;br /&gt;
[4] J. Barbič and D. L. James, “Real-time subspace integration for st. venant-kirchhoff deformable models,” ACM TOG, 2005.&lt;br /&gt;
[5] L. Fulton, V. Modi, D. Duvenaud, D. I. W. Levin, and A. Jacobson, “Latent-space dynamics for reduced deformable simulation,” Computer Graphics Forum, 2019.&lt;br /&gt;
[6] E. De Aguiar, L. Sigal, A. Treuille, and J. K. Hodgins, “Stable spaces for real-time clothing,” ACM TOG, 2010.&lt;br /&gt;
[7] D. Holden, B. C. Duong, S. Datta, and D. Nowrouzezahrai, “Subspace neural physics: fast data-driven interactive simulation,” in Proceedings of the 18th annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation. ACM, 2019.&lt;br /&gt;
[8] Q. Tan, Z. Pan, L. Gao, and D. Manocha, “Realtime simulation of thin-shell deformable materials using cnn-based mesh embedding,” arXiv preprint arXiv:1909.12354, 2019.&lt;/p&gt;

&lt;p&gt;new control ours

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/b_Agzln2qWw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;new control predictor

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ckX0NKs-uIg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;hole

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/6IoxsE7JdVE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;fem

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/tE4UZ3trZBA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Realtime Simulation of Thin-Shell Deformable Materials using CNN-Based Mesh Embedding</title>
      <link>/publication/cloth_embedding/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/publication/cloth_embedding/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
