[{"authors":["admin"],"categories":null,"content":"I am Qingyang Tan. I am a Ph.D. student at University of Maryland, College Park. I received the B.Eng. degree in Computer Science and Technology from University of Chinese Academy of Sciences.\nCurrently, I am a research assistant at UMIACS advised by Prof. Dinesh Manocha.\nBefore that, I conducted my undegraduate thesis in VIPL Group at Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), under the supervision of Prof. Xilin Chen and Prof. Xiujuan Chai. Before that, I interned in Human Motion Research Group at ICT, CAS, supervised by Prof. Lin Gao, Prof. Yu-Kun Lai and Prof. Shihong Xia. I also have serveral research experiences in interdisciplinary science, including UROP projects in Institute of Medical Engineering \u0026amp; Science and MIT Sloan School of Management of MIT, and synthetic biology project for the International Genetically Engineered Machine (iGEM) competition.\nHere is my resume. Please feel free to contact me.\n","date":1570147200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1570147200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am Qingyang Tan. I am a Ph.D. student at University of Maryland, College Park. I received the B.Eng. degree in Computer Science and Technology from University of Chinese Academy of Sciences.\nCurrently, I am a research assistant at UMIACS advised by Prof. Dinesh Manocha.\nBefore that, I conducted my undegraduate thesis in VIPL Group at Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), under the supervision of Prof.","tags":null,"title":"Qingyang Tan","type":"authors"},{"authors":["Qingyang Tan","Tingxiang Fan","Jia Pan","Dinesh Manocha"],"categories":null,"content":"","date":1570147200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570147200,"objectID":"d6e81ef202b8f4ae1a55e826d615ca27","permalink":"/publication/global_planning/","publishdate":"2019-10-04T00:00:00Z","relpermalink":"/publication/global_planning/","section":"publication","summary":"We present a novel algorithm (DeepMNavigate) for global multi-agent navigation in dense scenarios using deep reinforcement learning. Our approach uses local and global information for each robot based on motion information maps. We demonstrate the performance on complex, dense benchmarks with narrow passages on environments with tens of agents. We highlight the algorithm’s beneﬁts over prior learning methods and geometric decentralized algorithms in complex scenarios.","tags":["Planning"],"title":"DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local \u0026 Global Collision","type":"publication"},{"authors":["Qingyang Tan","Zherong Pan","Lin Gao","Dinesh Manocha"],"categories":null,"content":"","date":1569456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569456000,"objectID":"b977cfba30da8b37985e3fcd2b176391","permalink":"/publication/cloth_embedding/","publishdate":"2019-09-26T00:00:00Z","relpermalink":"/publication/cloth_embedding/","section":"publication","summary":"We address the problem of accelerating thin-shell deformable object simulations by dimension reduction. We present a new algorithm to embed a high-dimensional conﬁguration space of deformable objects in a low-dimensional feature space, where the conﬁgurations of objects and feature points have approximate one-to-one mapping.","tags":["Cloth","Mesh Embedding"],"title":"Realtime Simulation of Thin-Shell Deformable Materials using CNN-Based Mesh Embedding","type":"publication"},{"authors":null,"categories":null,"content":" Authors\nQingyang Tan (qytan@cs.umd.edu)\nDunbang He (dhe@terpmail.umd.edu)\nShuangqi Luo (sklaw@umd.edu)\n1. Research Goal In this project, we want to build a planner for multi-robot system, using local and global information and dividing policy decision process into two phases. We want to leverage the power of reinforcement learning, and train the policy in a simulation scenario, instead of using real-word training data.\nThere exist successful decentralized methods [1, 2, 3] based on reinforcement learning to navigate multi-robot system to avoid collision. Decentralized method does not require frequent communication and only uses local observation; However, with improvement of communication and positioning technology, e.g. 5G network and wifi-based indoor positioning system, we can more easily acquire global system status. Meanwhile, centralized system can guarantee safety, completeness, and approximate optimality solution [1]. Thus, in this project, we want to build a system using global information and computation in a simulated environment. To reduce complexity, we also assume the system has no communication latency and has a clear global sensor measurement.\nWe plan to formulate global information as a map with each agent’s location. This formulation can fit most of large systems no matter how many agents the system have. Also, we can use sophisticated convolutional neural network (CNN) to process this image-like input, to better understand the running environment.\nWe cannot deny that fully-centralized method has some drawbacks compared to fully distributed methods. For example, fully-centralized method computation rely on one central server. The central server may cannot process huge-amount of information, or the system may break down once the central server stopped. Thus, in this project, we want to divide the planner into two phases, i.e. global decision period with global information on central computer and local decision period with each agent’s own observation on its processor. Previous work including [4] shows that this idea could work. We want to combine deep reinforcement learning in this project.\nIn sum, our main goal of this research project is to build a multi-robot planner, combining local and global observation, deviding decision into two phases, and using deep reinforcement learning. We want to build our system on top of previous work [1], and demonstrate its planning result for multi-robot system on different scenarios.\nAt the end of the semester, we want to compare with state-of-art methods in two possible directions:\n Handling more complicated system with more robots involved; Generating a faster global plan for each robot reaching its own goal.  2. Motivation While humans and animals most of time navigate their lives based on local information, which is obtained through their natural perceptions, the underlying planning process may not yield the optimal result. For example, traffic throughput rarely reaches its theoretical maximum because people tend to change their speed based on local observations and thus causing traffic waves that lead to traffic congestion, as shown in the following video.\n  Therefore, we want to investigate, in a multi-robot system, how the overall performance of navigation measured in time could benefit from the extra input of global information.\n3. Related work Narain et al. [4] present a hybrid representation for large dense crowds with discrete agents using a dual representation both as discrete agents and as a single continuous system. The scalable crowd simulation approach makes it possible to simulate very large, dense crowds at near-interactive rates on desktop.\nFan et al. [1] develop a fully decentralized multi-robot collision avoidance framework, where each robot makes navigation decisions independently without any communication with others. A sensor-level collision avoidance policy that maps raw sensor measurements to an agent’s steering commands in terms of the movement velocity is learned via reinforcement learning. The learned policy is combined with traditional control approaches to further improve policy’s robustness and effectiveness.\nKhan et al. [6] cast the multi-agent reinforcement learning problem as a distributed optimization problem, assuming that for multi-agent settings, policies of individual agents in a given population live close to each other in parameter space and can be approximated by a single policy. Yoon et al. [7] extend the framework of centralized training with decentralized execution to include additional optimization of the inter-agent communication. Sadhu et al. [8] propose consensus-based multi-agent Q-learning to address the bottleneck of the optimal equilibrium selection among multiple types. Kim et al. [9] propose a new training method named message-dropout, yielding efficient learning for multi-agent deep reinforcement learning with information exchange with large input dimensions. Mirowski et al. [10] presents an end-to-end deep reinforcement learning approach that can be applied to real world visual navigation through city-scale environments.\n4. Plan Timeline:  Early March: Review of more previous work related to this project Mid March - Late March: Reproduce some related work, e.g. [1];\nCreate simulator for this project Early Apri - Mid April: Develop our system; train on simulator Late April - Early May: Test our final system; write report  References [1] Tingxiang Fan, Pinxin Long, Wenxi Liu, Jia Pan. Fully Distributed Multi-Robot Collision Avoidance via Deep Reinforcement Learning for Safe and Efficient Navigation in Complex Scenarios. arXiv, 2018\n[2] Pinxin Long, Tingxiang Fan, Xinyi Liao, Wenxi Liu, Hao Zhang, Jia Pan. Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning. International Conference on Robotics and Automation (ICRA), 2018.\n[3] Pinxin Long, Wenxi Liu, Jia Pan. Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation. IEEE Robotics and Automation Letters, 2(2), 656-663, 2017.\n[4] Rahul Narain, Abhinav Golas, Sean Curtis, Ming C. Lin. Aggregate Dynamics for Dense Crowd Simulation. SIGGRAPH Asia 2009\n[5] Rios-Torres, Jackeline, and Andreas A. Malikopoulos. \u0026ldquo;A survey on the coordination of connected and automated vehicles at intersections and merging at highway on-ramps.\u0026rdquo; IEEE Transactions on Intelligent Transportation Systems 18.5 (2017): 1066-1077.\n[6] Khan, Arbaaz, et al. \u0026ldquo;Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy Gradients.\u0026rdquo; arXiv preprint arXiv:1805.08776 (2018).\n[7] Yoon, Hyung-Jin, et al. \u0026ldquo;Learning to Communicate: A Machine Learning Framework for Heterogeneous Multi-Agent Robotic Systems.\u0026rdquo; AIAA Scitech 2019 Forum. 2019.\n[8] Sadhu, Arup Kumar, et al. \u0026ldquo;Multi-robot cooperative planning by consensus Q-learning.\u0026rdquo; 2017 International Joint Conference on Neural Networks (IJCNN). IEEE, 2017.\n[9] Kim, Woojun, Myungsik Cho, and Youngchul Sung. \u0026ldquo;Message-Dropout: An Efficient Training Method for Multi-Agent Deep Reinforcement Learning.\u0026rdquo; arXiv preprint arXiv:1902.06527 (2019).\n[10] Mirowski, Piotr, et al. \u0026ldquo;Learning to navigate in cities without a map.\u0026rdquo; Advances in Neural Information Processing Systems. 2018.\n","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"65f2d645c3b9e68f98a1e85e545ac638","permalink":"/project/818n/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/project/818n/","section":"project","summary":"In this project, we want to build a planner for multi-robot system, using local and global information and dividing policy decision process into two phases. We want to leverage the power of reinforcement learning, and train the policy in a simulation scenario, instead of using real-word training data.","tags":["course-project","robotics","deep-learning","motion-planning","reinforcement-learning"],"title":"Deep Combined Reinforcement Learning Planner for Multi-Robot System","type":"project"},{"authors":["Qingyang Tan","Lin Gao","Yu-Kun Lai","Shihong Xia"],"categories":null,"content":"","date":1529366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529366400,"objectID":"2d8f5f9c7a92f80c3891ba2f5bffc4b5","permalink":"/publication/vae/","publishdate":"2018-06-19T00:00:00Z","relpermalink":"/publication/vae/","section":"publication","summary":"We propose a novel framework which we call mesh variational autoencoders, to explore the probabilistic latent space of 3D surfaces. The framework is easy to train, and requires very few training examples. We also propose an extended model which allows flexibly adjusting the significance of different latent variables by altering the prior distribution.","tags":["Mesh Embedding","VAE"],"title":"Variational Autoencoders for Deforming 3D Mesh Models","type":"publication"},{"authors":["Qingyang Tan","Xiujuan Chai","Xilin Chen"],"categories":null,"content":"","date":1527206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527206400,"objectID":"a92e62f6b79cabc0191dc9dc940815cd","permalink":"/publication/sign_language/","publishdate":"2018-05-25T00:00:00Z","relpermalink":"/publication/sign_language/","section":"publication","summary":"We propose to combine the identification of key temporal and spatial regions and sign language classification into one deep learning network architecture, using attention mechanisms to focus on effective features, and realizing end-to-end automatic sign language recognition. Our proposed architecture can enhance the efficiency of sign language recognition and maintain a comparable recognition accuracy with state-of-art work.","tags":["Sign Language"],"title":"Attention-based Isolated Gesture Recognition with Multi-task Learning","type":"publication"},{"authors":["Qingyang Tan","Lin Gao","Yu-Kun Lai","Jie Yang","Shihong Xia"],"categories":null,"content":"","date":1517529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517529600,"objectID":"7f2e22d4dbe0b9c975a38913b9f79073","permalink":"/publication/sparse/","publishdate":"2018-02-02T00:00:00Z","relpermalink":"/publication/sparse/","section":"publication","summary":"We propose a novel mesh-based autoencoder architecture that is able to cope with meshes with irregular topology. We introduce sparse regularization in this framework, which along with convolutional operations, helps localize mesh deformations. Our framework is capable of extracting localized deformation components from mesh data sets with large-scale deformations and is robust to noise.","tags":["Mesh Embedding","AE"],"title":"Mesh-based Autoencoders for Localized Deformation Component Analysis","type":"publication"}]