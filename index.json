[{"authors":["admin"],"categories":null,"content":"I am Qingyang Tan. I am a Ph.D. student at University of Maryland, College Park. I received the B.Eng. degree in Computer Science and Technology from University of Chinese Academy of Sciences.\nCurrently, I am a research assistant at UMIACS advised by Prof. Dinesh Manocha.\nBefore that, I conducted my undegraduate thesis in VIPL Group at Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), under the supervision of Prof. Xilin Chen and Prof. Xiujuan Chai. Before that, I interned in Human Motion Research Group at ICT, CAS, supervised by Prof. Lin Gao, Prof. Yu-Kun Lai and Prof. Shihong Xia. I also have serveral research experiences in interdisciplinary science, including UROP projects in Institute of Medical Engineering \u0026amp; Science and MIT Sloan School of Management of MIT, and synthetic biology project for the International Genetically Engineered Machine (iGEM) competition.\nHere is my resume. Please feel free to contact me.\n","date":1570147200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1570147200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am Qingyang Tan. I am a Ph.D. student at University of Maryland, College Park. I received the B.Eng. degree in Computer Science and Technology from University of Chinese Academy of Sciences.\nCurrently, I am a research assistant at UMIACS advised by Prof. Dinesh Manocha.\nBefore that, I conducted my undegraduate thesis in VIPL Group at Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), under the supervision of Prof.","tags":null,"title":"Qingyang Tan","type":"authors"},{"authors":null,"categories":null,"content":" Author\nQingyang Tan (qytan@cs.umd.edu)\nAbstract\nIn this project, we want to build a cloth simulator in a nonlinear subspace to reduce the search space. We leverage the graph-based convolutional neural network (GCNN) with a physical-inspired loss term to build an embedding network for cloth models. We then use mass-spring systems or finite-element method (FEM) to model the cloth energy and build a simulator based on the nonlinear embedded space. We show that using the proposed method can better capture cloth deformation and generalize on new control information well.\nIntroduction Cloth simulation has applications in different areas, including animation, robotic control, gaming. Usually, the cloth is modeled as a 2D thin-shell object in a 3D space and represented by a high-resolution mesh. Many techniques have been developed to simulate the deformation of cloth in this mesh-based representation, including the mass-spring systems [1], the finite-element method [2]. However, the complexity of these methods depends on the number of degrees of freedoms (DOF), vary from $\\mathcal{O}(n^{1.5})$ to $\\mathcal{O}(n^{3})$. It would be hard to deploy high-resolution cloth simulation on devices with limited computation resources, e.g., cell phones.\nData-driven methods have been proposed to accelerate the simulation process. These kinds of methods leverage the results from pre-computation to accelerate run-time simulation process. Previous works including non-learning methods, such as motion graph [3], and learning-based methods, such as subspace simulation [4, 5] and frame predictor [6, 7]. However, previous methods may suffer from loss of details or freedom of new control information.\nIn our project, we propose to combine GCNN based neural network embedding [8] and subspace integration to capture more details of cloth deformation while allowing full freedom to control the cloth simulation.\nRelated Work We will briefly discuss previous works in this section.\nMotion Graph\n[3] proposes to incrementally construct a secondary cloth motion to capture almost everything in the system and then compress the raw mesh data from tens of gigabytes to only tens of megabytes. This method allows the system to capture the effect of high-resolution, off-line cloth simulation for a rich space of character motion and deliver it efﬁciently as part of an interactive application. However, the simulation is fully constrained by pre-computation and it can only deliver results explored during construction. We want to use subspace integration to give users full control of the cloth simulation process.\nSubspace Integration\n[4, 5] both conduct subspace integration to accelerate model simulation. [4] uses mass-scaled principal component analysis (mass-PCA), which is a linear model. [5] uses a fully-connected autoencoder based on PCA results, which is not computationally efficient and is constrained with the linear PCA basis. Thus, both methods cannot capture the nonlinear deformation well of cloth material. We propose to leverage the power of GCNN to exploit the subspace of cloth models and increase the accuracy of deformation.\nFrame Predictor\n[6, 7] use machine learning methods to model the simulation process of cloth. Use linear regression or neural network-based method to predict the next frame given control parameters and previous few frames. These methods can be very quick since they do not require heavy computation of the physics model. However, this scheme can easily let the system be overfitted on training data, and it would behave badly on the new unseen control information, as we will show in the result section. So we stick to model the physics law explicitly.\nProposed Method GCNN-based Embedding\nIn this section, we provide an overview of low-dimensional embedding of the cloth meshes. Our goal is to obtain a subspace through a set of $N$ deformed cloth meshes, $S_m$, with each mesh represented using a set of $K$ vertices, denoted as $\\mathbf{p}_m\\in\\mathbb{R}^{3K}$.\nWe denote the $i$th vertex as $\\mathbf{p}_{m,i}\\in\\mathbb{R}^3$. Here $m=1,\\cdots,N$ and $i=1,\\cdots,K$. These vertices are connected by edges, so we can define the 1-ring neighbor set, $\\mathcal{N}^1_i$, and the 2-ring neighbor set, $\\mathcal{N}^2_i$, for each $\\mathbf{p}_i$. Our goal is to find a map $\\mathbf{z}\\to\\mathbf{p}$, where $\\mathbf{z}$ is a low-dimensional feature and $\\mathbf{p}\\in\\mathbf{R}^{3K}$ such that, for each $m$, there exists a $\\mathbf{z}_m$ where $\\mathbf{z}_m$ is mapped to a mesh close to $\\mathbf{p}_m$. To define such a function $\\mathbf{D}$, we use graph-based CNN and ACAP features [8] to represent large-scale deformations.\nWe define $\\mathbf{D}$ as a graph-based CNN using local filters $$ \\mathbf{D}\\triangleq\\mathbf{C}_L^T\\cdots\\mathbf{C}_2^T\\circ\\mathbf{C}_1^T\\circ\\mathbf{F}^T, $$ where $L$ is the number of convolutional layers and $\\mathbf{C}^T$ is the transpose of a graph-based convolutional operator, $\\mathbf{F}$ is a fully connected layer. Each layer is appended by a leaky ReLU activation layer.\nA graph-based convolutional layer is a linear operator defined as: $$ \\mathbf{C}(\\mathbf{x})_i = \\mathbf{W}\\mathbf{x}_i+\\mathbf{W_N}(\\Sigma_j\\mathbf{x}_j)/N_i + b $$ where $\\mathbf{W},\\mathbf{W_N}, b$ are optimizable weights and biases, respectively; $j$ is the index of neighbors of $i$ and $N_i$ is the degree of vertex $i$.\nAll the weights in the CNN are trained in a self-supervised manner using an autoencoder and a reconstruction loss in ACAP feature and physical-inspired loss mentioned in the later section.\nModel the Physics of Cloth Deformation\nExperimental Results Conclusion References\n[1] K.-J. Choi and H.-S. Ko, “Stable but responsive cloth,” in SIGGRAPH 2002.\n[2] R. Narain, A. Samii, and J. F. O’Brien, “Adaptive anisotropic remeshing for cloth simulation,” ACM TOG, 2002.\n[3] D. Kim, W. Koh, R. Narain, K. Fatahalian, A. Treuille, and J. F. O’Brien, “Near-exhaustive precomputation of secondary cloth effects,” ACM TOG, 2013.\n[4] J. Barbič and D. L. James, “Real-time subspace integration for st. venant-kirchhoff deformable models,” ACM TOG, 2005.\n[5] L. Fulton, V. Modi, D. Duvenaud, D. I. W. Levin, and A. Jacobson, “Latent-space dynamics for reduced deformable simulation,” Computer Graphics Forum, 2019.\n[6] E. De Aguiar, L. Sigal, A. Treuille, and J. K. Hodgins, “Stable spaces for real-time clothing,” ACM TOG, 2010.\n[7] D. Holden, B. C. Duong, S. Datta, and D. Nowrouzezahrai, “Subspace neural physics: fast data-driven interactive simulation,” in Proceedings of the 18th annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation. ACM, 2019.\n[8] Q. Tan, Z. Pan, L. Gao, and D. Manocha, “Realtime simulation of thin-shell deformable materials using cnn-based mesh embedding,” arXiv preprint arXiv:1909.12354, 2019.\nnew control ours   new control predictor   hole   fem   ","date":1576540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576540800,"objectID":"e70c561291c02232432b90a00423f8fb","permalink":"/project/828x/","publishdate":"2019-12-17T00:00:00Z","relpermalink":"/project/828x/","section":"project","summary":"Author\nQingyang Tan (qytan@cs.umd.edu)\nAbstract\nIn this project, we want to build a cloth simulator in a nonlinear subspace to reduce the search space. We leverage the graph-based convolutional neural network (GCNN) with a physical-inspired loss term to build an embedding network for cloth models. We then use mass-spring systems or finite-element method (FEM) to model the cloth energy and build a simulator based on the nonlinear embedded space. We show that using the proposed method can better capture cloth deformation and generalize on new control information well.","tags":["Cloth"],"title":"Nonlinear Subspace Cloth Simulation","type":"project"},{"authors":["Qingyang Tan","Tingxiang Fan","Jia Pan","Dinesh Manocha"],"categories":null,"content":"","date":1570147200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570147200,"objectID":"d6e81ef202b8f4ae1a55e826d615ca27","permalink":"/publication/global_planning/","publishdate":"2019-10-04T00:00:00Z","relpermalink":"/publication/global_planning/","section":"publication","summary":"We present a novel algorithm (DeepMNavigate) for global multi-agent navigation in dense scenarios using deep reinforcement learning. Our approach uses local and global information for each robot based on motion information maps. We demonstrate the performance on complex, dense benchmarks with narrow passages on environments with tens of agents. We highlight the algorithm’s beneﬁts over prior learning methods and geometric decentralized algorithms in complex scenarios.","tags":["Planning"],"title":"DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local \u0026 Global Collision","type":"publication"},{"authors":["Qingyang Tan","Zherong Pan","Lin Gao","Dinesh Manocha"],"categories":null,"content":"","date":1569456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569456000,"objectID":"b977cfba30da8b37985e3fcd2b176391","permalink":"/publication/cloth_embedding/","publishdate":"2019-09-26T00:00:00Z","relpermalink":"/publication/cloth_embedding/","section":"publication","summary":"We address the problem of accelerating thin-shell deformable object simulations by dimension reduction. We present a new algorithm to embed a high-dimensional conﬁguration space of deformable objects in a low-dimensional feature space, where the conﬁgurations of objects and feature points have approximate one-to-one mapping.","tags":["Cloth","Mesh Embedding"],"title":"Realtime Simulation of Thin-Shell Deformable Materials using CNN-Based Mesh Embedding","type":"publication"},{"authors":null,"categories":null,"content":" Authors\nQingyang Tan (qytan@cs.umd.edu)\nDunbang He (dhe@terpmail.umd.edu)\nShuangqi Luo (sklaw@umd.edu)\n1. Research Goal In this project, we want to build a planner for multi-robot system, using local and global information and dividing policy decision process into two phases. We want to leverage the power of reinforcement learning, and train the policy in a simulation scenario, instead of using real-word training data.\nThere exist successful decentralized methods [1, 2, 3] based on reinforcement learning to navigate multi-robot system to avoid collision. Decentralized method does not require frequent communication and only uses local observation; However, with improvement of communication and positioning technology, e.g. 5G network and wifi-based indoor positioning system, we can more easily acquire global system status. Meanwhile, centralized system can guarantee safety, completeness, and approximate optimality solution [1]. Thus, in this project, we want to build a system using global information and computation in a simulated environment. To reduce complexity, we also assume the system has no communication latency and has a clear global sensor measurement.\nWe plan to formulate global information as a map with each agent’s location. This formulation can fit most of large systems no matter how many agents the system have. Also, we can use sophisticated convolutional neural network (CNN) to process this image-like input, to better understand the running environment.\nWe cannot deny that fully-centralized method has some drawbacks compared to fully distributed methods. For example, fully-centralized method computation rely on one central server. The central server may cannot process huge-amount of information, or the system may break down once the central server stopped. Thus, in this project, we want to divide the planner into two phases, i.e. global decision period with global information on central computer and local decision period with each agent’s own observation on its processor. Previous work including [4] shows that this idea could work. We want to combine deep reinforcement learning in this project.\nIn sum, our main goal of this research project is to build a multi-robot planner, combining local and global observation, deviding decision into two phases, and using deep reinforcement learning. We want to build our system on top of previous work [1], and demonstrate its planning result for multi-robot system on different scenarios.\nAt the end of the semester, we want to compare with state-of-art methods in two possible directions:\n Handling more complicated system with more robots involved; Generating a faster global plan for each robot reaching its own goal.  2. Motivation While humans and animals most of time navigate their lives based on local information, which is obtained through their natural perceptions, the underlying planning process may not yield the optimal result. For example, traffic throughput rarely reaches its theoretical maximum because people tend to change their speed based on local observations and thus causing traffic waves that lead to traffic congestion, as shown in the following video.\n  Therefore, we want to investigate, in a multi-robot system, how the overall performance of navigation measured in time could benefit from the extra input of global information.\n3. Related work Narain et al. [4] present a hybrid representation for large dense crowds with discrete agents using a dual representation both as discrete agents and as a single continuous system. The scalable crowd simulation approach makes it possible to simulate very large, dense crowds at near-interactive rates on desktop.\nFan et al. [1] develop a fully decentralized multi-robot collision avoidance framework, where each robot makes navigation decisions independently without any communication with others. A sensor-level collision avoidance policy that maps raw sensor measurements to an agent’s steering commands in terms of the movement velocity is learned via reinforcement learning. The learned policy is combined with traditional control approaches to further improve policy’s robustness and effectiveness.\nKhan et al. [6] cast the multi-agent reinforcement learning problem as a distributed optimization problem, assuming that for multi-agent settings, policies of individual agents in a given population live close to each other in parameter space and can be approximated by a single policy. Yoon et al. [7] extend the framework of centralized training with decentralized execution to include additional optimization of the inter-agent communication. Sadhu et al. [8] propose consensus-based multi-agent Q-learning to address the bottleneck of the optimal equilibrium selection among multiple types. Kim et al. [9] propose a new training method named message-dropout, yielding efficient learning for multi-agent deep reinforcement learning with information exchange with large input dimensions. Mirowski et al. [10] presents an end-to-end deep reinforcement learning approach that can be applied to real world visual navigation through city-scale environments.\n4. Plan Timeline:  Early March: Review of more previous work related to this project Mid March - Late March: Reproduce some related work, e.g. [1];\nCreate simulator for this project Early Apri - Mid April: Develop our system; train on simulator Late April - Early May: Test our final system; write report  References [1] Tingxiang Fan, Pinxin Long, Wenxi Liu, Jia Pan. Fully Distributed Multi-Robot Collision Avoidance via Deep Reinforcement Learning for Safe and Efficient Navigation in Complex Scenarios. arXiv, 2018\n[2] Pinxin Long, Tingxiang Fan, Xinyi Liao, Wenxi Liu, Hao Zhang, Jia Pan. Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning. International Conference on Robotics and Automation (ICRA), 2018.\n[3] Pinxin Long, Wenxi Liu, Jia Pan. Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation. IEEE Robotics and Automation Letters, 2(2), 656-663, 2017.\n[4] Rahul Narain, Abhinav Golas, Sean Curtis, Ming C. Lin. Aggregate Dynamics for Dense Crowd Simulation. SIGGRAPH Asia 2009\n[5] Rios-Torres, Jackeline, and Andreas A. Malikopoulos. \u0026ldquo;A survey on the coordination of connected and automated vehicles at intersections and merging at highway on-ramps.\u0026rdquo; IEEE Transactions on Intelligent Transportation Systems 18.5 (2017): 1066-1077.\n[6] Khan, Arbaaz, et al. \u0026ldquo;Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy Gradients.\u0026rdquo; arXiv preprint arXiv:1805.08776 (2018).\n[7] Yoon, Hyung-Jin, et al. \u0026ldquo;Learning to Communicate: A Machine Learning Framework for Heterogeneous Multi-Agent Robotic Systems.\u0026rdquo; AIAA Scitech 2019 Forum. 2019.\n[8] Sadhu, Arup Kumar, et al. \u0026ldquo;Multi-robot cooperative planning by consensus Q-learning.\u0026rdquo; 2017 International Joint Conference on Neural Networks (IJCNN). IEEE, 2017.\n[9] Kim, Woojun, Myungsik Cho, and Youngchul Sung. \u0026ldquo;Message-Dropout: An Efficient Training Method for Multi-Agent Deep Reinforcement Learning.\u0026rdquo; arXiv preprint arXiv:1902.06527 (2019).\n[10] Mirowski, Piotr, et al. \u0026ldquo;Learning to navigate in cities without a map.\u0026rdquo; Advances in Neural Information Processing Systems. 2018.\n","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"65f2d645c3b9e68f98a1e85e545ac638","permalink":"/project/818n/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/project/818n/","section":"project","summary":"In this project, we want to build a planner for multi-robot system, using local and global information and dividing policy decision process into two phases. We want to leverage the power of reinforcement learning, and train the policy in a simulation scenario, instead of using real-word training data.","tags":["Planning"],"title":"Deep Combined Reinforcement Learning Planner for Multi-Robot System","type":"project"},{"authors":["Qingyang Tan","Lin Gao","Yu-Kun Lai","Shihong Xia"],"categories":null,"content":"","date":1529366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529366400,"objectID":"2d8f5f9c7a92f80c3891ba2f5bffc4b5","permalink":"/publication/vae/","publishdate":"2018-06-19T00:00:00Z","relpermalink":"/publication/vae/","section":"publication","summary":"We propose a novel framework which we call mesh variational autoencoders, to explore the probabilistic latent space of 3D surfaces. The framework is easy to train, and requires very few training examples. We also propose an extended model which allows flexibly adjusting the significance of different latent variables by altering the prior distribution.","tags":["Mesh Embedding","VAE"],"title":"Variational Autoencoders for Deforming 3D Mesh Models","type":"publication"},{"authors":["Qingyang Tan","Xiujuan Chai","Xilin Chen"],"categories":null,"content":"","date":1527206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527206400,"objectID":"a92e62f6b79cabc0191dc9dc940815cd","permalink":"/publication/sign_language/","publishdate":"2018-05-25T00:00:00Z","relpermalink":"/publication/sign_language/","section":"publication","summary":"We propose to combine the identification of key temporal and spatial regions and sign language classification into one deep learning network architecture, using attention mechanisms to focus on effective features, and realizing end-to-end automatic sign language recognition. Our proposed architecture can enhance the efficiency of sign language recognition and maintain a comparable recognition accuracy with state-of-art work.","tags":["Sign Language"],"title":"Attention-based Isolated Gesture Recognition with Multi-task Learning","type":"publication"},{"authors":["Qingyang Tan","Lin Gao","Yu-Kun Lai","Jie Yang","Shihong Xia"],"categories":null,"content":"","date":1517529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517529600,"objectID":"7f2e22d4dbe0b9c975a38913b9f79073","permalink":"/publication/sparse/","publishdate":"2018-02-02T00:00:00Z","relpermalink":"/publication/sparse/","section":"publication","summary":"We propose a novel mesh-based autoencoder architecture that is able to cope with meshes with irregular topology. We introduce sparse regularization in this framework, which along with convolutional operations, helps localize mesh deformations. Our framework is capable of extracting localized deformation components from mesh data sets with large-scale deformations and is robust to noise.","tags":["Mesh Embedding","AE"],"title":"Mesh-based Autoencoders for Localized Deformation Component Analysis","type":"publication"}]