<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>QINGYANG TAN</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>QINGYANG TAN</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019 Qingyang Tan</copyright><lastBuildDate>Mon, 16 Dec 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>QINGYANG TAN</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Nonlinear Subspace Cloth Simulation</title>
      <link>/project/828x/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/project/828x/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br /&gt;
Qingyang Tan (&lt;a href=&#34;mailto:qytan@cs.umd.edu&#34; target=&#34;_blank&#34;&gt;qytan@cs.umd.edu&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;br /&gt;
In this project, we want to build a cloth simulator in a nonlinear subspace to reduce the search space. We leverage the graph-based convolutional neural network (GCNN) with a physical-inspired loss term to build an embedding network for cloth models. We then use mass-spring systems or finite-element method (FEM) to model the cloth energy and build a simulator based on the nonlinear embedded space. We show that using the proposed method can better capture cloth deformation and generalize on new control information well.&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Cloth simulation has applications in different areas, including animation, robotic control, gaming. Usually, the cloth is modeled as a 2D thin-shell object in a 3D space and represented by a high-resolution mesh. Many techniques have been developed to simulate the deformation of cloth in this mesh-based representation, including the mass-spring systems [1], the finite-element method [2]. However, the complexity of these methods depends on the number of degrees of freedoms (DOF), vary from $\mathcal{O}(n^{1.5})$ to $\mathcal{O}(n^{3})$. It would be hard to deploy high-resolution cloth simulation on devices with limited computation resources, e.g., cell phones.&lt;/p&gt;

&lt;p&gt;Data-driven methods have been proposed to accelerate the simulation process. These kinds of methods leverage the results from pre-computation to accelerate run-time simulation process. Previous works including non-learning methods, such as motion graph [3], and learning-based methods, such as subspace simulation [4, 5] and frame predictor [6, 7]. However, previous methods may suffer from loss of details or freedom of new control information.&lt;/p&gt;

&lt;p&gt;In our project, we propose to combine GCNN based neural network embedding [8] and subspace integration to capture more details of cloth deformation while allowing full freedom to control the cloth simulation.&lt;/p&gt;

&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;

&lt;p&gt;We will briefly discuss previous works in this section.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Motion Graph&lt;/strong&gt;&lt;br /&gt;
[3] proposes to incrementally construct a secondary cloth motion to capture almost everything in the system and then compress the raw mesh data from tens of gigabytes to only tens of megabytes. This method allows the system to capture the effect of high-resolution, off-line cloth simulation for a rich space of character motion and deliver it efﬁciently as part of an interactive application. However, the simulation is fully constrained by pre-computation and it can only deliver results explored during construction. We want to use subspace integration to give users full control of the cloth simulation process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subspace Integration&lt;/strong&gt;&lt;br /&gt;
[4, 5] both conduct subspace integration to accelerate model simulation. [4] uses mass-scaled principal component analysis (mass-PCA), which is a linear model. [5] uses a fully-connected autoencoder based on PCA results, which is not computationally efficient and is constrained with the linear PCA basis. Thus, both methods cannot capture the nonlinear deformation well of cloth material. We propose to leverage the power of GCNN to exploit the subspace of cloth models and increase the accuracy of deformation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Frame Predictor&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;proposed-method&#34;&gt;Proposed Method&lt;/h2&gt;

&lt;h2 id=&#34;experimental-results&#34;&gt;Experimental Results&lt;/h2&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;br /&gt;
[1] K.-J. Choi and H.-S. Ko, “Stable but responsive cloth,” in SIGGRAPH 2002.&lt;br /&gt;
[2] R. Narain, A. Samii, and J. F. O’Brien, “Adaptive anisotropic remeshing for cloth simulation,”  ACM TOG, 2002.&lt;br /&gt;
[3] D. Kim, W. Koh, R. Narain, K. Fatahalian, A. Treuille, and J. F. O’Brien, “Near-exhaustive precomputation of secondary cloth effects,” ACM TOG, 2013.&lt;br /&gt;
[4] J. Barbič and D. L. James, “Real-time subspace integration for st. venant-kirchhoff deformable models,” ACM TOG, 2005.&lt;br /&gt;
[5] L. Fulton, V. Modi, D. Duvenaud, D. I. W. Levin, and A. Jacobson, “Latent-space dynamics for reduced deformable simulation,” Computer Graphics Forum, 2019.&lt;br /&gt;
[6] E. De Aguiar, L. Sigal, A. Treuille, and J. K. Hodgins, “Stable spaces for real-time clothing,” ACM TOG, 2010.&lt;br /&gt;
[7] D. Holden, B. C. Duong, S. Datta, and D. Nowrouzezahrai, “Subspace neural physics: fast data-driven interactive simulation,” in Proceedings of the 18th annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation. ACM, 2019.&lt;br /&gt;
[8] Q. Tan, Z. Pan, L. Gao, and D. Manocha, “Realtime simulation of thin-shell deformable materials using cnn-based mesh embedding,” arXiv preprint arXiv:1909.12354, 2019.&lt;/p&gt;

&lt;p&gt;new control ours

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/b_Agzln2qWw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;new control predictor

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ckX0NKs-uIg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;hole

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/6IoxsE7JdVE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;fem

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/tE4UZ3trZBA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local &amp; Global Collision</title>
      <link>/publication/global_planning/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/publication/global_planning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Realtime Simulation of Thin-Shell Deformable Materials using CNN-Based Mesh Embedding</title>
      <link>/publication/cloth_embedding/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/publication/cloth_embedding/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Combined Reinforcement Learning Planner for Multi-Robot System</title>
      <link>/project/818n/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/project/818n/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt;&lt;br /&gt;
Qingyang Tan (&lt;a href=&#34;mailto:qytan@cs.umd.edu&#34; target=&#34;_blank&#34;&gt;qytan@cs.umd.edu&lt;/a&gt;)&lt;br /&gt;
Dunbang He (&lt;a href=&#34;mailto:dhe@terpmail.umd.edu&#34; target=&#34;_blank&#34;&gt;dhe@terpmail.umd.edu&lt;/a&gt;)&lt;br /&gt;
Shuangqi Luo (&lt;a href=&#34;mailto:sklaw@umd.edu&#34; target=&#34;_blank&#34;&gt;sklaw@umd.edu&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/robotics_planning.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;1-research-goal&#34;&gt;1. Research Goal&lt;/h1&gt;

&lt;p&gt;In this project, we want to build a planner for multi-robot system, using local and global information and dividing policy decision process into two phases. We want to leverage the power of reinforcement learning, and train the policy in a simulation scenario, instead of using real-word training data.&lt;/p&gt;

&lt;p&gt;There exist successful decentralized methods [1, 2, 3] based on reinforcement learning to navigate multi-robot system to avoid collision. Decentralized method does not require frequent communication and only uses local observation; However, with improvement of communication and positioning technology, e.g. 5G network and wifi-based indoor positioning system, we can more easily acquire global system status. Meanwhile, centralized system can guarantee safety, completeness, and approximate optimality solution [1]. Thus, in this project, we want to build a system using global information and computation in a simulated environment. To reduce complexity, we also assume the system has no communication latency and has a clear global sensor measurement.&lt;/p&gt;

&lt;p&gt;We plan to formulate global information as a map with each agent’s location. This formulation can fit most of large systems no matter how many agents the system have. Also, we can use sophisticated convolutional neural network (CNN) to process this image-like input, to better understand the running environment.&lt;/p&gt;

&lt;p&gt;We cannot deny that fully-centralized method has some drawbacks compared to fully distributed methods. For example, fully-centralized method computation rely on one central server. The central server may cannot process huge-amount of information, or the system may break down once the central server stopped. Thus, in this project, we want to divide the planner into two phases, i.e. global decision period with global information on central computer and local decision period with each agent’s own observation on its processor. Previous work including [4] shows that this idea could work. We want to combine deep reinforcement learning in this project.&lt;/p&gt;

&lt;p&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;In sum, our main goal of this research project is to build a multi-robot planner, combining local and global observation, deviding decision into two phases, and using deep reinforcement learning. We want to build our system on top of previous work [1], and demonstrate its planning result for multi-robot system on different scenarios.&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;At the end of the semester, we want to compare with state-of-art methods in two possible directions:&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;Handling more complicated system with more robots involved;&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/li&gt;
&lt;li&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;Generating a faster global plan for each robot reaching its own goal.&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;2-motivation&#34;&gt;2. Motivation&lt;/h1&gt;

&lt;p&gt;While humans and animals most of time navigate their lives based on local information, which is obtained through their natural perceptions, the underlying planning process may not yield the optimal result. For example, traffic throughput rarely reaches its theoretical maximum because people tend to change their speed based on local observations and thus causing traffic waves that lead to traffic congestion, as shown in the following video.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Suugn-p5C1M&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Therefore, we want to investigate, in a multi-robot system, how the overall performance of navigation measured in time could benefit from the extra input of global information.&lt;/p&gt;

&lt;h1 id=&#34;3-related-work&#34;&gt;3. Related work&lt;/h1&gt;

&lt;p&gt;Narain et al. [4] present a hybrid representation for large dense crowds with discrete agents using a dual representation both as discrete agents and as a single continuous system. The scalable crowd simulation approach makes it possible to simulate very large, dense crowds at near-interactive rates on desktop.&lt;/p&gt;

&lt;p&gt;Fan et al. [1] develop a fully decentralized multi-robot collision avoidance framework, where each robot makes navigation decisions independently without any communication with others. A sensor-level collision avoidance policy that maps raw sensor measurements to an agent’s steering commands in terms of the movement velocity is learned via reinforcement learning. The learned policy is combined with traditional control approaches to further improve policy’s robustness and effectiveness.&lt;/p&gt;

&lt;p&gt;Khan et al. [6] cast the multi-agent reinforcement learning problem as a distributed optimization problem, assuming that for multi-agent settings, policies of individual agents in a given population live close to each other in parameter space and can be approximated by a single policy. Yoon et al. [7] extend the framework of centralized training with decentralized execution to include additional optimization of the inter-agent communication. Sadhu et al. [8] propose consensus-based multi-agent Q-learning to address the bottleneck of the optimal equilibrium selection among multiple types. Kim et al. [9] propose a new training method named message-dropout, yielding efficient learning for multi-agent deep reinforcement learning with information exchange with large input dimensions. Mirowski et al. [10] presents an end-to-end deep reinforcement learning approach that can be applied to real world visual navigation through city-scale environments.&lt;/p&gt;

&lt;h1 id=&#34;4-plan&#34;&gt;4. Plan&lt;/h1&gt;

&lt;h2 id=&#34;timeline&#34;&gt;Timeline:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Early March: Review of more previous work related to this project&lt;/li&gt;
&lt;li&gt;Mid March - Late March:
Reproduce some related work, e.g. [1];&lt;br /&gt;
Create simulator for this project&lt;/li&gt;
&lt;li&gt;Early Apri - Mid April: Develop our system; train on simulator&lt;/li&gt;
&lt;li&gt;Late April - Early May: Test our final system; write report&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;p&gt;[1] Tingxiang Fan, Pinxin Long, Wenxi Liu, Jia Pan. Fully Distributed Multi-Robot Collision Avoidance via Deep Reinforcement Learning for Safe and Efficient Navigation in Complex Scenarios. arXiv, 2018&lt;br /&gt;
[2] Pinxin Long, Tingxiang Fan, Xinyi Liao, Wenxi Liu, Hao Zhang, Jia Pan. Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning. International Conference on Robotics and Automation (ICRA), 2018.&lt;br /&gt;
[3] Pinxin Long, Wenxi Liu, Jia Pan. Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation. IEEE Robotics and Automation Letters, 2(2), 656-663, 2017.&lt;br /&gt;
[4] Rahul Narain, Abhinav Golas, Sean Curtis, Ming C. Lin. Aggregate Dynamics for Dense Crowd Simulation. SIGGRAPH Asia 2009&lt;br /&gt;
[5] Rios-Torres, Jackeline, and Andreas A. Malikopoulos. &amp;ldquo;A survey on the coordination of connected and automated vehicles at intersections and merging at highway on-ramps.&amp;rdquo; IEEE Transactions on Intelligent Transportation Systems 18.5 (2017): 1066-1077.&lt;br /&gt;
[6] Khan, Arbaaz, et al. &amp;ldquo;Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy Gradients.&amp;rdquo; arXiv preprint arXiv:1805.08776 (2018).&lt;br /&gt;
[7] Yoon, Hyung-Jin, et al. &amp;ldquo;Learning to Communicate: A Machine Learning Framework for Heterogeneous Multi-Agent Robotic Systems.&amp;rdquo; AIAA Scitech 2019 Forum. 2019.&lt;br /&gt;
[8] Sadhu, Arup Kumar, et al. &amp;ldquo;Multi-robot cooperative planning by consensus Q-learning.&amp;rdquo; 2017 International Joint Conference on Neural Networks (IJCNN). IEEE, 2017.&lt;br /&gt;
[9] Kim, Woojun, Myungsik Cho, and Youngchul Sung. &amp;ldquo;Message-Dropout: An Efficient Training Method for Multi-Agent Deep Reinforcement Learning.&amp;rdquo; arXiv preprint arXiv:1902.06527 (2019).&lt;br /&gt;
[10] Mirowski, Piotr, et al. &amp;ldquo;Learning to navigate in cities without a map.&amp;rdquo; Advances in Neural Information Processing Systems. 2018.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variational Autoencoders for Deforming 3D Mesh Models</title>
      <link>/publication/vae/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      <guid>/publication/vae/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Attention-based Isolated Gesture Recognition with Multi-task Learning</title>
      <link>/publication/sign_language/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      <guid>/publication/sign_language/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mesh-based Autoencoders for Localized Deformation Component Analysis</title>
      <link>/publication/sparse/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      <guid>/publication/sparse/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
