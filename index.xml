<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>QINGYANG TAN</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>QINGYANG TAN</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019 Qingyang Tan</copyright><lastBuildDate>Tue, 17 Dec 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>QINGYANG TAN</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Nonlinear Subspace Cloth Simulation</title>
      <link>/project/828x/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/project/828x/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br /&gt;
Qingyang Tan (&lt;a href=&#34;mailto:qytan@cs.umd.edu&#34; target=&#34;_blank&#34;&gt;qytan@cs.umd.edu&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;br /&gt;
In this project, we want to build a cloth simulator in a nonlinear subspace to reduce the search space. We leverage the graph-based convolutional neural network (GCNN) with a physical-inspired loss term to build an embedding network for cloth models. We then use mass-spring systems or finite-element method (FEM) to model the cloth energy and build a simulator based on the nonlinear embedded space. We show that using the proposed method can better capture cloth deformation and generalize on new control information well.&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Cloth simulation has applications in different areas, including animation, robotic control, gaming. Usually, the cloth is modeled as a 2D thin-shell object in a 3D space and represented by a high-resolution mesh. Many techniques have been developed to simulate the deformation of cloth in this mesh-based representation, including the mass-spring systems [1], the finite-element method [2]. However, the complexity of these methods depends on the number of degrees of freedoms (DOF), vary from $\mathcal{O}(n^{1.5})$ to $\mathcal{O}(n^{3})$. It would be hard to deploy high-resolution cloth simulation on devices with limited computation resources, e.g., cell phones.&lt;/p&gt;

&lt;p&gt;Data-driven methods have been proposed to accelerate the simulation process. These kinds of methods leverage the results from pre-computation to accelerate run-time simulation process. Previous works including non-learning methods, such as motion graph [3], and learning-based methods, such as subspace simulation [4, 5] and frame predictor [6, 7]. However, previous methods may suffer from loss of details or freedom of new control information.&lt;/p&gt;

&lt;p&gt;In our project, we propose to combine GCNN based neural network embedding [8] and subspace integration to capture more details of cloth deformation while allowing full freedom to control the cloth simulation.&lt;/p&gt;

&lt;h2 id=&#34;related-work&#34;&gt;&lt;strong&gt;Related Work&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;We will briefly discuss previous works in this section.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Motion Graph&lt;/strong&gt;&lt;br /&gt;
[3] proposes to incrementally construct a secondary cloth motion to capture almost everything in the system and then compress the raw mesh data from tens of gigabytes to only tens of megabytes. This method allows the system to capture the effect of high-resolution, off-line cloth simulation for a rich space of character motion and deliver it efﬁciently as part of an interactive application. However, the simulation is fully constrained by pre-computation and it can only deliver results explored during construction. We want to use subspace integration to give users full control of the cloth simulation process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subspace Integration&lt;/strong&gt;&lt;br /&gt;
[4, 5] both conduct subspace integration to accelerate model simulation. [4] uses mass-scaled principal component analysis (mass-PCA), which is a linear model. [5] uses a fully-connected autoencoder based on PCA results, which is not computationally efficient and is constrained with the linear PCA basis. Thus, both methods cannot capture the nonlinear deformation well of cloth material. We propose to leverage the power of GCNN to exploit the subspace of cloth models and increase the accuracy of deformation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Frame Predictor&lt;/strong&gt;&lt;br /&gt;
[6, 7] use machine learning methods to model the simulation process of cloth. Use linear regression or neural network-based method to predict the next frame given control parameters and previous few frames. These methods can be very quick since they do not require heavy computation of the physics model. However, this scheme can easily let the system be overfitted on training data, and it would behave badly on the new unseen control information, as we will show in the result section. So we stick to model the physics law explicitly.&lt;/p&gt;

&lt;h2 id=&#34;proposed-method&#34;&gt;&lt;strong&gt;Proposed Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;GCNN-based Embedding&lt;/strong&gt;&lt;br /&gt;
In this section, we provide an overview of low-dimensional embedding of the cloth meshes. Our goal is to obtain a subspace through a set of $N$ deformed cloth meshes, $S_m$, with each mesh represented using a set of $K$ vertices, denoted as $\mathbf{p}_m\in\mathbb{R}^{3K}$.&lt;/p&gt;

&lt;p&gt;We denote the $i$th vertex as $\mathbf{p}_{m,i}\in\mathbb{R}^3$. Here $m=1,\cdots,N$ and $i=1,\cdots,K$. These vertices are connected by edges, so we can define the 1-ring neighbor set, $\mathcal{N}^1_i$, and the 2-ring neighbor set, $\mathcal{N}^2_i$, for each $\mathbf{p}_i$. Our goal is to find a map $\mathbf{z}\to\mathbf{p}$, where $\mathbf{z}$ is a low-dimensional feature and $\mathbf{p}\in\mathbf{R}^{3K}$ such that, for each $m$, there exists a $\mathbf{z}_m$ where $\mathbf{z}_m$ is mapped to a mesh close to $\mathbf{p}_m$. To define such a function $\mathbf{D}$, we use graph-based CNN and ACAP features [9] to represent large-scale deformations.&lt;/p&gt;

&lt;p&gt;We define $\mathbf{D}$ as a graph-based CNN using local filters
$$
\mathbf{D}\triangleq\mathbf{C}_L^T\cdots\mathbf{C}_2^T\circ\mathbf{C}_1^T\circ\mathbf{F}^T,
$$
where $L$ is the number of convolutional layers and $\mathbf{C}^T$ is the transpose of a graph-based convolutional operator, $\mathbf{F}$ is a fully connected layer. Each layer is appended by a leaky ReLU activation layer.&lt;/p&gt;

&lt;p&gt;A graph-based convolutional layer is a linear operator defined as:
$$
\mathbf{C}(\mathbf{x})_i = \mathbf{W}\mathbf{x}_i+\mathbf{W_N}(\Sigma_j\mathbf{x}_j)/N_i + b,
$$
where $\mathbf{W},\mathbf{W_N}, b$ are optimizable weights and biases, respectively; $j$ is the index of neighbors of $i$ and $N_i$ is the degree of vertex $i$.&lt;/p&gt;

&lt;p&gt;The following figure shows the network architecture:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/NN.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;All the weights in the CNN are trained in a self-supervised manner using an autoencoder and a reconstruction loss in ACAP feature and physical-inspired loss mentioned in the later section.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model the Physics of Cloth Deformation in Subspace&lt;/strong&gt;&lt;br /&gt;
We assumes that cloth sequence could be  generated using a physics simulator that solves a continuous-time PDE of the form:
\begin{align}
\mathbf{M}\frac{\partial \mathbf{p}}{\partial t}=-\mathbf{force}(\mathbf{p},\mathbf{q}),
\end{align}
where $\mathbf{M}$ is the mass matrix and $t$ is the time. $\mathbf{force}(\mathbf{p},\mathbf{q})$ models internal and external forces affecting the current mesh $\mathbf{p}$. The force is also a function of the current control parameters $\mathbf{q}$. This continuous-time PDE can be discretized into $N$ timesteps such that $S_m$ is the position of the cloth at time instance $i\Delta t$, where $\Delta t$ is the timestep size. A discrete physics simulator can determine all $\mathbf{p}_m$ given the initial condition $\mathbf{p}_1,\mathbf{p}_2$ and the sequence of control parameters $\mathbf{q}_1,\mathbf{q}_2,\cdots,\mathbf{q}_N$ by the recurrent function:
&lt;img src=&#34;/img/eq1.png&#34; alt=&#34;&#34; /&gt;
where $f$ is a discretization of the continuous-time PDE. To define this discretization, we reformulates $f$ as the following optimization:
&lt;img src=&#34;/img/eq2.png&#34; alt=&#34;&#34; /&gt;
Here the first term models the kinematic energy, which requires each vertex to move in its own velocity as much as possible if no external forces are exerted. The second term models forces caused by various potential energies at configuration $\mathbf{p}$. In this work, we consider three kinds of potential energy:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Gravitational energy $\mathcal{P}_g(\mathbf{p})=-\sum_i\mathbf{g}^T\mathbf{M}\mathbf{p}_i$, where $\mathbf{g}$ is the gravitational acceleration vector.&lt;/li&gt;
&lt;li&gt;Stretch resistance energy, $\mathcal{P}_s$, models the potential force induced by stretching the material.&lt;/li&gt;
&lt;li&gt;Bending resistance energy, $\mathcal{P}_b$, models the potential force induced by bending the material.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many ways to discretize $\mathcal{P}_s,\mathcal{P}_b$, such as the finite element method used in [2] or the mass-spring model used in [1]. Both formulations are evaluated in this work.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;[1] models the stretch resistance term, $\mathcal{P}_s$, as a set of Hooke&amp;rsquo;s springs between each vertex and vertices in its 1-ring neighbors. In addition, the bend resistance term, $\mathcal{P}_b$, is defined as another set of Hooke&amp;rsquo;s springs between each vertex and vertices in its 2-ring neighbors.&lt;/li&gt;
&lt;li&gt;[2] models the stretch resistance term, $\mathcal{P}_s$, as a linear elastic energy resisting the in-plane deformations of each mesh triangle. In addition, the bend resistance term, $\mathcal{P}_b$, is defined as a quadratic penalty term resisting the change of the dihedral angle between any pair of two neighboring triangles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We use the physical term defined for the optimization problem for training the autoencoder. This should improve the accuracy of the embedded shapes.&lt;/p&gt;

&lt;p&gt;After the training of the autoencoder, we get the subspace of the cloth models, and the mapping $\mathbf{p} = \mathbf{D}(\mathbf{z})$, we can rewrite the optimization problem as
&lt;img src=&#34;/img/eq3.png&#34; alt=&#34;&#34; /&gt;
Using the new optimization problem, we can reduce the search space, and accelerate the process of cloth simulation.&lt;/p&gt;

&lt;h2 id=&#34;implementation&#34;&gt;&lt;strong&gt;Implementation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;We build the neural network with the TensorFlow package and implemented the mass-spring model and FEM with C++ customized TensorFlow operation. We use the optimization method from the Scipy package to run the cloth simulation. Specifically, we use the L-BGFS-B method.&lt;/p&gt;

&lt;h2 id=&#34;experimental-results&#34;&gt;&lt;strong&gt;Experimental Results&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Embedding Comparison&lt;/strong&gt;&lt;br /&gt;
We first compare the reconstruction ability of our subspace with previous methods. In this experiment, we create 2 sequences using [1] with $N=2400$ frames. The first sequence has $K=4224$ vertices with no holes, while the second sequence has $K=4165$ vertices with holes. During the comparison, for each dataset, we select the first 12 frames in every 17 frames to form the training set. The other frames are used as the test set. We compare several metrics: 1) the root mean square error, $\mathcal{M}$&lt;sub&gt;rms&lt;/sub&gt;; 2) the STED metric, $\mathcal{M}$&lt;sub&gt;STED&lt;/sub&gt;, measuring the visual quality; 3) the physical metric, $\mathcal{M}$&lt;sub&gt;phys&lt;/sub&gt;, measuring the norm of partial derivatives of $\mathcal{L}_{phys}$. The results are shown in the following table:
&lt;img src=&#34;/img/table.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;These suggest that our method using GCNN backbone network with physical-inspired loss can better capture the deformation of cloth.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;New Control Parameter Comparison&lt;/strong&gt;&lt;br /&gt;
We claim in the previous section that previous methods using frame predictor such as [7] could not generalize on new control parameters well, here we give an example:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ckX0NKs-uIg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;The generated sequence is unstable and has clear drawbacks on the four corners.&lt;/p&gt;

&lt;p&gt;Meanwhile, since our method directly models the physical terms behind cloth deformation, it can perform well in this situation:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/b_Agzln2qWw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Different Topology&lt;/strong&gt;&lt;br /&gt;
We show an example of cloth with holes:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/6IoxsE7JdVE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;FEM-based Results&lt;/strong&gt;&lt;br /&gt;
We show an example using FEM to model the potential energy:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/tE4UZ3trZBA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h2 id=&#34;conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;In sum, in this project,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;we build a non-linear GCNN-based subspace simulator for cloth deformation;&lt;/li&gt;
&lt;li&gt;we include different physics modeling methods, the mass-spring system, and FEM.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Due to time limitation, the system still has some drawbacks, we want to improve the work in the following ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;we want to move full computation to GPU, to accelerate the simulation process;&lt;/li&gt;
&lt;li&gt;we want to use more accurate optimization method, right now we only use a quasi-Newton method;&lt;/li&gt;
&lt;li&gt;we want to add collision detection in the whole pipeline, maybe still through data-driven methods.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;br /&gt;
[1] K.-J. Choi and H.-S. Ko, “Stable but responsive cloth,” in SIGGRAPH 2002.&lt;br /&gt;
[2] R. Narain, A. Samii, and J. F. O’Brien, “Adaptive anisotropic remeshing for cloth simulation,”  ACM TOG, 2002.&lt;br /&gt;
[3] D. Kim, W. Koh, R. Narain, K. Fatahalian, A. Treuille, and J. F. O’Brien, “Near-exhaustive precomputation of secondary cloth effects,” ACM TOG, 2013.&lt;br /&gt;
[4] J. Barbič and D. L. James, “Real-time subspace integration for st. venant-kirchhoff deformable models,” ACM TOG, 2005.&lt;br /&gt;
[5] L. Fulton, V. Modi, D. Duvenaud, D. I. W. Levin, and A. Jacobson, “Latent-space dynamics for reduced deformable simulation,” Computer Graphics Forum, 2019.&lt;br /&gt;
[6] E. De Aguiar, L. Sigal, A. Treuille, and J. K. Hodgins, “Stable spaces for real-time clothing,” ACM TOG, 2010.&lt;br /&gt;
[7] D. Holden, B. C. Duong, S. Datta, and D. Nowrouzezahrai, “Subspace neural physics: fast data-driven interactive simulation,” in Proceedings of the 18th annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation. ACM, 2019.&lt;br /&gt;
[8] Q. Tan, Z. Pan, L. Gao, and D. Manocha, “Realtime simulation of thin-shell deformable materials using cnn-based mesh embedding,” arXiv preprint arXiv:1909.12354, 2019.&lt;br /&gt;
[9] L. Gao, Y.-K. Lai, J. Yang, L.-X. Zhang, L. Kobbelt, and S. Xia, “Sparse Data Driven Mesh Deformation,” IEEE TVCG, 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local &amp; Global Collision</title>
      <link>/publication/global_planning/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/publication/global_planning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Realtime Simulation of Thin-Shell Deformable Materials using CNN-Based Mesh Embedding</title>
      <link>/publication/cloth_embedding/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/publication/cloth_embedding/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Combined Reinforcement Learning Planner for Multi-Robot System</title>
      <link>/project/818n/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/project/818n/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt;&lt;br /&gt;
Qingyang Tan (&lt;a href=&#34;mailto:qytan@cs.umd.edu&#34; target=&#34;_blank&#34;&gt;qytan@cs.umd.edu&lt;/a&gt;)&lt;br /&gt;
Dunbang He (&lt;a href=&#34;mailto:dhe@terpmail.umd.edu&#34; target=&#34;_blank&#34;&gt;dhe@terpmail.umd.edu&lt;/a&gt;)&lt;br /&gt;
Shuangqi Luo (&lt;a href=&#34;mailto:sklaw@umd.edu&#34; target=&#34;_blank&#34;&gt;sklaw@umd.edu&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/robotics_planning.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;1-research-goal&#34;&gt;1. Research Goal&lt;/h1&gt;

&lt;p&gt;In this project, we want to build a planner for multi-robot system, using local and global information and dividing policy decision process into two phases. We want to leverage the power of reinforcement learning, and train the policy in a simulation scenario, instead of using real-word training data.&lt;/p&gt;

&lt;p&gt;There exist successful decentralized methods [1, 2, 3] based on reinforcement learning to navigate multi-robot system to avoid collision. Decentralized method does not require frequent communication and only uses local observation; However, with improvement of communication and positioning technology, e.g. 5G network and wifi-based indoor positioning system, we can more easily acquire global system status. Meanwhile, centralized system can guarantee safety, completeness, and approximate optimality solution [1]. Thus, in this project, we want to build a system using global information and computation in a simulated environment. To reduce complexity, we also assume the system has no communication latency and has a clear global sensor measurement.&lt;/p&gt;

&lt;p&gt;We plan to formulate global information as a map with each agent’s location. This formulation can fit most of large systems no matter how many agents the system have. Also, we can use sophisticated convolutional neural network (CNN) to process this image-like input, to better understand the running environment.&lt;/p&gt;

&lt;p&gt;We cannot deny that fully-centralized method has some drawbacks compared to fully distributed methods. For example, fully-centralized method computation rely on one central server. The central server may cannot process huge-amount of information, or the system may break down once the central server stopped. Thus, in this project, we want to divide the planner into two phases, i.e. global decision period with global information on central computer and local decision period with each agent’s own observation on its processor. Previous work including [4] shows that this idea could work. We want to combine deep reinforcement learning in this project.&lt;/p&gt;

&lt;p&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;In sum, our main goal of this research project is to build a multi-robot planner, combining local and global observation, deviding decision into two phases, and using deep reinforcement learning. We want to build our system on top of previous work [1], and demonstrate its planning result for multi-robot system on different scenarios.&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;At the end of the semester, we want to compare with state-of-art methods in two possible directions:&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;Handling more complicated system with more robots involved;&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/li&gt;
&lt;li&gt;&lt;font size=4&gt;&lt;strong&gt;&lt;em&gt;Generating a faster global plan for each robot reaching its own goal.&lt;/em&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;2-motivation&#34;&gt;2. Motivation&lt;/h1&gt;

&lt;p&gt;While humans and animals most of time navigate their lives based on local information, which is obtained through their natural perceptions, the underlying planning process may not yield the optimal result. For example, traffic throughput rarely reaches its theoretical maximum because people tend to change their speed based on local observations and thus causing traffic waves that lead to traffic congestion, as shown in the following video.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Suugn-p5C1M&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Therefore, we want to investigate, in a multi-robot system, how the overall performance of navigation measured in time could benefit from the extra input of global information.&lt;/p&gt;

&lt;h1 id=&#34;3-related-work&#34;&gt;3. Related work&lt;/h1&gt;

&lt;p&gt;Narain et al. [4] present a hybrid representation for large dense crowds with discrete agents using a dual representation both as discrete agents and as a single continuous system. The scalable crowd simulation approach makes it possible to simulate very large, dense crowds at near-interactive rates on desktop.&lt;/p&gt;

&lt;p&gt;Fan et al. [1] develop a fully decentralized multi-robot collision avoidance framework, where each robot makes navigation decisions independently without any communication with others. A sensor-level collision avoidance policy that maps raw sensor measurements to an agent’s steering commands in terms of the movement velocity is learned via reinforcement learning. The learned policy is combined with traditional control approaches to further improve policy’s robustness and effectiveness.&lt;/p&gt;

&lt;p&gt;Khan et al. [6] cast the multi-agent reinforcement learning problem as a distributed optimization problem, assuming that for multi-agent settings, policies of individual agents in a given population live close to each other in parameter space and can be approximated by a single policy. Yoon et al. [7] extend the framework of centralized training with decentralized execution to include additional optimization of the inter-agent communication. Sadhu et al. [8] propose consensus-based multi-agent Q-learning to address the bottleneck of the optimal equilibrium selection among multiple types. Kim et al. [9] propose a new training method named message-dropout, yielding efficient learning for multi-agent deep reinforcement learning with information exchange with large input dimensions. Mirowski et al. [10] presents an end-to-end deep reinforcement learning approach that can be applied to real world visual navigation through city-scale environments.&lt;/p&gt;

&lt;h1 id=&#34;4-plan&#34;&gt;4. Plan&lt;/h1&gt;

&lt;h2 id=&#34;timeline&#34;&gt;Timeline:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Early March: Review of more previous work related to this project&lt;/li&gt;
&lt;li&gt;Mid March - Late March:
Reproduce some related work, e.g. [1];&lt;br /&gt;
Create simulator for this project&lt;/li&gt;
&lt;li&gt;Early Apri - Mid April: Develop our system; train on simulator&lt;/li&gt;
&lt;li&gt;Late April - Early May: Test our final system; write report&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;p&gt;[1] Tingxiang Fan, Pinxin Long, Wenxi Liu, Jia Pan. Fully Distributed Multi-Robot Collision Avoidance via Deep Reinforcement Learning for Safe and Efficient Navigation in Complex Scenarios. arXiv, 2018&lt;br /&gt;
[2] Pinxin Long, Tingxiang Fan, Xinyi Liao, Wenxi Liu, Hao Zhang, Jia Pan. Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning. International Conference on Robotics and Automation (ICRA), 2018.&lt;br /&gt;
[3] Pinxin Long, Wenxi Liu, Jia Pan. Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation. IEEE Robotics and Automation Letters, 2(2), 656-663, 2017.&lt;br /&gt;
[4] Rahul Narain, Abhinav Golas, Sean Curtis, Ming C. Lin. Aggregate Dynamics for Dense Crowd Simulation. SIGGRAPH Asia 2009&lt;br /&gt;
[5] Rios-Torres, Jackeline, and Andreas A. Malikopoulos. &amp;ldquo;A survey on the coordination of connected and automated vehicles at intersections and merging at highway on-ramps.&amp;rdquo; IEEE Transactions on Intelligent Transportation Systems 18.5 (2017): 1066-1077.&lt;br /&gt;
[6] Khan, Arbaaz, et al. &amp;ldquo;Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy Gradients.&amp;rdquo; arXiv preprint arXiv:1805.08776 (2018).&lt;br /&gt;
[7] Yoon, Hyung-Jin, et al. &amp;ldquo;Learning to Communicate: A Machine Learning Framework for Heterogeneous Multi-Agent Robotic Systems.&amp;rdquo; AIAA Scitech 2019 Forum. 2019.&lt;br /&gt;
[8] Sadhu, Arup Kumar, et al. &amp;ldquo;Multi-robot cooperative planning by consensus Q-learning.&amp;rdquo; 2017 International Joint Conference on Neural Networks (IJCNN). IEEE, 2017.&lt;br /&gt;
[9] Kim, Woojun, Myungsik Cho, and Youngchul Sung. &amp;ldquo;Message-Dropout: An Efficient Training Method for Multi-Agent Deep Reinforcement Learning.&amp;rdquo; arXiv preprint arXiv:1902.06527 (2019).&lt;br /&gt;
[10] Mirowski, Piotr, et al. &amp;ldquo;Learning to navigate in cities without a map.&amp;rdquo; Advances in Neural Information Processing Systems. 2018.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variational Autoencoders for Deforming 3D Mesh Models</title>
      <link>/publication/vae/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      <guid>/publication/vae/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Attention-based Isolated Gesture Recognition with Multi-task Learning</title>
      <link>/publication/sign_language/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      <guid>/publication/sign_language/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mesh-based Autoencoders for Localized Deformation Component Analysis</title>
      <link>/publication/sparse/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      <guid>/publication/sparse/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
